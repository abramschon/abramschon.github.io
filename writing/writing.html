<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="../stylesheets/style.css">
    <title>brAM's writing</title>
</head>
<body>
<div id="page">
    <nav>
        <ul class="nav_bar">
            <li class = "bram"><a href="../index.html">&#8594; brAM's</a></li>
            <li>writing,</li>
            <li><a href="../cv/cv.html">&#8594; CV,</a></li>
            <li><a href="../contact/contact.html">&#8594; contact details</a></li>
        </ul>
    </nav>

    <header>
        <h1> <pre class="bram"> misc. <br> writing </pre></h1>
    </header>

    <section>
        <article>
            <h2><a href="papers/InterpretabilityRL.pdf" target="_blank">&#8594; An Exploration of Interpretability in Reinforcement Learning (2020)</a></h2> 
            <p>
                <span class="bold">Reinforcement Learning</span> (RL) is a powerful and general field of artificial intelligence that provides a means to learn <span class="bold">optimal strategies</span>, 
                or policies, to achieve <span class="bold">specified goals</span>. Although RL models have surpassed both human and other machine-learning models’ performance in a number of domains, 
                the policies that they learn can <span class="bold">seldom be understood</span> by humans, especially <span class="bold">non-experts</span>. 
                <span class="bold">Explainable artificial intelligence</span> (XAI) is a field that focuses on developing AI models that can be <span class="bold">interpreted</span> by humans. 
                Given AI’s, and specifically RL’s, potential and current use in <span class="bold">contexts that impact humans</span> (autonomous vehicles, advising policy, etc.), 
                there is a growing need for the <span class="bold">transparency</span> and <span class="bold">interpretability</span> of these models. 
                This project explores some of the current literature on interpretability in Reinforcement learning.  
            </p>

            <h2><a href="papers/Truncated_Levy_Flights_Crime.pdf" target="_blank">&#8594; Truncated Lévy Flights to Fight Crime (2019)</a></h2> 
            <p>
                This was my final undergraduate project. It centered around a model proposed in the 2018 paper 
                <span class = "bold" style="font-style: italic;">Crime modeling with truncated Lévy flights for residential burglary models</span> by <span class="bold">Pan et al.</span>
                After reproducing results from the original paper, an adapted model that considers the behaviour of  <span class="bold">individual agents</span> is simulated.
                This was done in part to demonstrate an understanding of the underlying model - what it <span class="bold">visually means</span> for agents to follow truncated Lévy flights, and how
                this individual behaviour relates to the emergent patterns observed in the probabilistic description.
            </p>
        </article>

        <aside>
            <p>Beyond learning how to write well, learning how to manage <span class="bold">(curate, store, index, sort)</span> my writing is an on-going process <span class="bold">(tips welcome)</span>. In the meanwhile, here is a selection of some of my academic writing over the past 2 years.</p>
        </aside>

    </section>

    <footer>
        <p>
            <span class="barcode">website by bram 2020</span>
        </p>
    </footer>

</div>
</body>
</html>